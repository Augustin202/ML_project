{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22fdb34b-cf0d-4737-8a8a-75eea6bb7c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "chemin=os.getcwd()\n",
    "os.chdir('./..')\n",
    "from hack_class import *\n",
    "#from hack_class import HackingModel\n",
    "os.chdir(chemin)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dc7f988-6c33-4277-af8b-2f2378f08cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, parser='auto')\n",
    "X = (X/255. - .5)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "029868d0-eb60-4550-93dd-bada2f0421a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dic={'rf':RandomForestClassifier(), 'tree':DecisionTreeClassifier(), 'logistic':LogisticRegression(C=30.0),\n",
    "      'knn':KNeighborsClassifier(), 'MLP':MLPClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ed9d97-c5bc-436b-b517-3694e749d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdels_list=['rf','tree','logistic','knn','MLP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bbf7f3e-38f6-45f3-90fa-1ddc8ca9584e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guspo\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\guspo\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\guspo\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "10it [00:04,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report, test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.36      0.50       200\n",
      "           1       0.59      0.93      0.72       200\n",
      "\n",
      "    accuracy                           0.64       400\n",
      "   macro avg       0.71      0.64      0.61       400\n",
      "weighted avg       0.71      0.64      0.61       400\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# save\\nfilename = \"./data/report_test_model_{}_{}.json\".format(\\'rf\\', num_fichier)\\nwith open(filename, \"w\") as json_file:\\n    json.dump(reports, json_file, indent=2)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model=models_dic['rf']\n",
    "model=MLPClassifier(hidden_layer_sizes=(100,), activation='logistic', solver='adam', alpha=0.0001, batch_size='auto', \n",
    "                    learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    "                    random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                    nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                    beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
    "num_fichier=1\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Target model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=200, train_size=200,stratify = y)\n",
    "rf_clf = clone(model)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "random.seed()\n",
    "\n",
    "reports=[]\n",
    "for i in range(1):\n",
    "    #on split les données en deux, on garde le set shadow qui va servir à entrainer les shadow models\n",
    "    X_shadow, temp, y_shadow, temp2 = train_test_split(X, y, test_size=100, train_size=100,stratify = y)\n",
    "    \n",
    "    models = [clone(model)]*2\n",
    "    test = HackingModel(RandomForestClassifier(n_estimators=100),models, X_shadow, y_shadow,\n",
    "                      list(set(y_shadow)),list(set(y_train)) )\n",
    "    report=test.print_score_hacking(X_train,y_train, X_test,y_test, rf_clf)\n",
    "    reports.append(report)\n",
    "'''\n",
    "# save\n",
    "filename = \"./data/report_test_model_{}_{}.json\".format('rf', num_fichier)\n",
    "with open(filename, \"w\") as json_file:\n",
    "    json.dump(reports, json_file, indent=2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d45ac21-036f-4b40-94a5-5dab9ac8ff2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guspo\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\guspo\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\guspo\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "10it [00:02,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report, test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.68       200\n",
      "           1       0.68      0.79      0.73       200\n",
      "\n",
      "    accuracy                           0.71       400\n",
      "   macro avg       0.72      0.71      0.71       400\n",
      "weighted avg       0.72      0.71      0.71       400\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# save\\nfilename = \"./data/report_test_model_{}_{}.json\".format(\\'rf\\', num_fichier)\\nwith open(filename, \"w\") as json_file:\\n    json.dump(reports, json_file, indent=2)\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model=models_dic['rf']\n",
    "model=MLPClassifier(hidden_layer_sizes=(40,), activation='logistic', solver='adam', alpha=0.0001, batch_size='auto', \n",
    "                    learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=400, shuffle=True, \n",
    "                    random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                    nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                    beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
    "num_fichier=1\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Target model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=200, train_size=200,stratify = y)\n",
    "rf_clf = clone(model)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "random.seed()\n",
    "\n",
    "reports=[]\n",
    "for i in range(1):\n",
    "    #on split les données en deux, on garde le set shadow qui va servir à entrainer les shadow models\n",
    "    X_shadow, temp, y_shadow, temp2 = train_test_split(X, y, test_size=100, train_size=100,stratify = y)\n",
    "    \n",
    "    models = [clone(model)]*2\n",
    "    test = HackingModel(RandomForestClassifier(n_estimators=100),models, X_shadow, y_shadow,\n",
    "                      list(set(y_shadow)),list(set(y_train)) )\n",
    "    report=test.print_score_hacking(X_train,y_train, X_test,y_test, rf_clf)\n",
    "    reports.append(report)\n",
    "'''\n",
    "# save\n",
    "filename = \"./data/report_test_model_{}_{}.json\".format('rf', num_fichier)\n",
    "with open(filename, \"w\") as json_file:\n",
    "    json.dump(reports, json_file, indent=2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cb6a9cfc-d821-4eb3-bef3-160f96f32cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.365\n",
      "Accuracy on test set: 0.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:04,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report, test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50       200\n",
      "           1       0.50      0.49      0.50       200\n",
      "\n",
      "    accuracy                           0.50       400\n",
      "   macro avg       0.50      0.50      0.50       400\n",
      "weighted avg       0.50      0.50      0.50       400\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# save\\nfilename = \"./data/report_test_model_{}_{}.json\".format(\\'rf\\', num_fichier)\\nwith open(filename, \"w\") as json_file:\\n    json.dump(reports, json_file, indent=2)\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model=models_dic['rf']\n",
    "model=LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.0001, fit_intercept=True, intercept_scaling=1, \n",
    "                         class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', \n",
    "                         verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "num_fichier=1\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Target model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=200, train_size=200,stratify = y)\n",
    "rf_clf = clone(model)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "random.seed()\n",
    "\n",
    "y_train_pred = rf_clf.predict(X_train)\n",
    "print(\"Accuracy on training set:\", accuracy_score(y_train, y_train_pred))\n",
    "#print(\"Classification report on training set:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = rf_clf.predict(X_test)\n",
    "print(\"Accuracy on test set:\", accuracy_score(y_test, y_test_pred))\n",
    "#print(\"Classification report on test set:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "reports=[]\n",
    "for i in range(1):\n",
    "    #on split les données en deux, on garde le set shadow qui va servir à entrainer les shadow models\n",
    "    X_shadow, temp, y_shadow, temp2 = train_test_split(X, y, test_size=100, train_size=100,stratify = y)\n",
    "    \n",
    "    models = [clone(model)]*2\n",
    "    test = HackingModel(RandomForestClassifier(n_estimators=100),models, X_shadow, y_shadow,\n",
    "                      list(set(y_shadow)),list(set(y_train)) )\n",
    "    report=test.print_score_hacking(X_train,y_train, X_test,y_test, rf_clf)\n",
    "    reports.append(report)\n",
    "'''\n",
    "# save\n",
    "filename = \"./data/report_test_model_{}_{}.json\".format('rf', num_fichier)\n",
    "with open(filename, \"w\") as json_file:\n",
    "    json.dump(reports, json_file, indent=2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "abe21863-7866-41fb-a52f-5f1bd98838ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.0\n",
      "Accuracy on test set: 0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:04,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report, test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.35      0.45       200\n",
      "           1       0.55      0.80      0.65       200\n",
      "\n",
      "    accuracy                           0.57       400\n",
      "   macro avg       0.59      0.57      0.55       400\n",
      "weighted avg       0.59      0.57      0.55       400\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# save\\nfilename = \"./data/report_test_model_{}_{}.json\".format(\\'rf\\', num_fichier)\\nwith open(filename, \"w\") as json_file:\\n    json.dump(reports, json_file, indent=2)\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model=models_dic['rf']\n",
    "model=LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10.001, fit_intercept=True, intercept_scaling=1, \n",
    "                         class_weight=None, random_state=None, solver='lbfgs', max_iter=300, multi_class='auto', \n",
    "                         verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "num_fichier=1\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Target model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=200, train_size=200,stratify = y)\n",
    "rf_clf = clone(model)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "random.seed()\n",
    "\n",
    "y_train_pred = rf_clf.predict(X_train)\n",
    "print(\"Accuracy on training set:\", accuracy_score(y_train, y_train_pred))\n",
    "#print(\"Classification report on training set:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = rf_clf.predict(X_test)\n",
    "print(\"Accuracy on test set:\", accuracy_score(y_test, y_test_pred))\n",
    "#print(\"Classification report on test set:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "\n",
    "reports=[]\n",
    "for i in range(1):\n",
    "    #on split les données en deux, on garde le set shadow qui va servir à entrainer les shadow models\n",
    "    X_shadow, temp, y_shadow, temp2 = train_test_split(X, y, test_size=100, train_size=100,stratify = y)\n",
    "    \n",
    "    models = [clone(model)]*2\n",
    "    test = HackingModel(RandomForestClassifier(n_estimators=100),models, X_shadow, y_shadow,\n",
    "                      list(set(y_shadow)),list(set(y_train)) )\n",
    "    report=test.print_score_hacking(X_train,y_train, X_test,y_test, rf_clf)\n",
    "    reports.append(report)\n",
    "'''\n",
    "# save\n",
    "filename = \"./data/report_test_model_{}_{}.json\".format('rf', num_fichier)\n",
    "with open(filename, \"w\") as json_file:\n",
    "    json.dump(reports, json_file, indent=2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "378468a9-2591-494c-bcd4-eae930b56b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['              precision    recall  f1-score   support',\n",
       " '',\n",
       " '    accuracy                           0.75       200',\n",
       " '   macro avg       0.80      0.74      0.74       200',\n",
       " 'weighted avg       0.79      0.75      0.74       200']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test, y_test_pred).split('\\n')[:2 ]+classification_report(y_test, y_test_pred).split('\\n')[-4:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc64d3e-9d62-4d33-a74d-693261d1e619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
