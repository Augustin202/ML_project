{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474960e5-80ad-40c6-a938-ea4d7171fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "chemin=os.getcwd()\n",
    "os.chdir('./..')\n",
    "from hack_class import *\n",
    "os.chdir(chemin)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "import sklearn.cluster\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import clone\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f707c-88f2-4ad1-8267-c00174678e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.read_csv('X_adult.csv')\n",
    "y=pd.read_csv('y_adult.csv')['predic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3a5da-b5a1-4649-a242-303f716b743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100, train_size=100,stratify = y)\n",
    "logistic_clf = LogisticRegression(C= 100)\n",
    "logistic_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3beb339-2744-49a6-bc69-b5ddfe6b3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on split les données en deux, on garde le set shadow qui va servir à entrainer les shadow models\n",
    "X_shadow, temp, y_shadow, temp2 = train_test_split(X, y, test_size=100, train_size=100,stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f861b6-edd4-4dc4-ba80-e455b0e0f5e1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#This class describes only one shadow model\n",
    "class  ShadowModel:\n",
    "    #takes a sklearn model, and datasets for training and testing\n",
    "    #list_y_class is the list of values that y can take\n",
    "    def __init__(self, model, X_train, X_test, y_train, y_test, liste_y_class):\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.liste_y_class = liste_y_class\n",
    "        self.model_fit(X_train, y_train)\n",
    "        self.model_pred_proba()\n",
    "\n",
    "    #fit self.model according to X and y\n",
    "    def model_fit(self,X,y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    #this function creates the database we will use for the hack model\n",
    "    #to every line of X, we have to add the prediction probabilities, and if wether or not it was in the training set\n",
    "    #this cell is a bit technical, because all the elements available in y might not match all the possible values of y\n",
    "    def model_pred_proba(self):\n",
    "        #results for the train set\n",
    "        predictions_df_temp = pd.DataFrame(self.model.predict_proba(self.X_train), columns=list(set(self.y_train))).reset_index(drop=True)\n",
    "        predictions_df = pd.DataFrame([[0]*len(self.liste_y_class) for i in range(len(predictions_df_temp))], columns=self.liste_y_class)\n",
    "        predictions_df[predictions_df_temp.columns]= predictions_df_temp\n",
    "\n",
    "        X_train_proba = pd.concat([self.X_train.reset_index(drop=True), predictions_df.reset_index(drop=True)],  axis=1)\n",
    "        X_train_proba['predic'] = self.y_train.reset_index(drop=True)\n",
    "        X_train_proba['entrainement'] = 1 #indicates that these elements where in the train set\n",
    "\n",
    "        #results for the test set\n",
    "        predictions_df_temp2 = pd.DataFrame(self.model.predict_proba(self.X_test), columns=list(set(self.y_train))).reset_index(drop=True)\n",
    "        predictions_df2 = pd.DataFrame([[0]*len(self.liste_y_class) for i in range(len(predictions_df_temp2))], columns=self.liste_y_class)\n",
    "        predictions_df2[predictions_df_temp2.columns]= predictions_df_temp2\n",
    "        X_test_proba = pd.concat([self.X_test.reset_index(drop=True), predictions_df2.reset_index(drop=True)],  axis=1)\n",
    "        X_test_proba['predic'] = self.y_test.reset_index(drop=True)\n",
    "        X_test_proba['entrainement'] = 0 #indicates that these elements where in the test set\n",
    "\n",
    "        self.X_proba = pd.concat([X_train_proba,X_test_proba])\n",
    "\n",
    "        \n",
    "#this class creates all the shadow models we are going to use. Hence it contains multiple shadow models.\n",
    "class ShadowModels:\n",
    "    #list_y_class contains all the values that y can take\n",
    "    def __init__(self, models, X, y,list_y_class):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.list_y_class = list_y_class\n",
    "        self.fit_models(models, list_y_class)\n",
    "        self.concatenate_data()\n",
    "\n",
    "    #this functions create a shadow model for every element of the list models\n",
    "    #modelsis a list of sklearn models. Dataset are equally split into dataset and training set\n",
    "    def fit_models(self, models,list_y_class):\n",
    "        n = len(self.X)//2\n",
    "        self.shadow_models = []\n",
    "        for model in models:\n",
    "            X_train, X_test, y_train, y_test=train_test_split(self.X, self.y, test_size = n, train_size= n,stratify = self.y)\n",
    "            self.shadow_models.append(ShadowModel(model, X_train, X_test, y_train, y_test,list_y_class))\n",
    "\n",
    "    #this function concatenates all the databases created by the shadow models, in order to create a dataframe for the hacking model\n",
    "    def concatenate_data(self):\n",
    "        data_attaquant= self.shadow_models[0].X_proba\n",
    "        for shadow_model in self.shadow_models[1:]:\n",
    "            data_attaquant = pd.concat([data_attaquant, shadow_model.X_proba],ignore_index=True ,axis=0)\n",
    "        self.data_attaquant = data_attaquant\n",
    "        \n",
    "        \n",
    "#this class trains the hacking model\n",
    "class HackingModel:\n",
    "\n",
    "    #entries : hack_model (sklearn model, the one we will train and will perform hacking), shadow_models (list of sklearn models that we will use as shadow models),\n",
    "    #list_y_class (all the values y can take), list_y_target_model (all the y values that were in the dataset used by the target model)\n",
    "    def __init__(self, hack_model, shadow_models, X, y, list_y_class,list_y_target_model):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.list_y_class = list_y_class\n",
    "        self.list_y_target_model = list_y_target_model\n",
    "        #creation of an object ShadowModels that contains all the ShadowModel we will use for hacking\n",
    "        self.shadowmodels = ShadowModels(shadow_models, X, y, list_y_class)\n",
    "        self.hack_models = {}\n",
    "        #we create a hack_model for each class of y\n",
    "        for class_y in self.list_y_class:\n",
    "            self.hack_models[class_y] = clone(hack_model)\n",
    "\n",
    "        self.set_data_per_class()\n",
    "        self.fit_hack_models()\n",
    "\n",
    "    #creates a list of datasets, corresponding to each value that y can take\n",
    "    def set_data_per_class(self):\n",
    "        self.list_entrainement = []\n",
    "        for class_y in self.list_y_class:\n",
    "            y = self.shadowmodels.data_attaquant[self.shadowmodels.data_attaquant['predic']==class_y].entrainement\n",
    "            X = self.shadowmodels.data_attaquant[self.shadowmodels.data_attaquant['predic']==class_y].drop(columns=['entrainement'])\n",
    "            X.columns = X.columns.astype(str)\n",
    "            self.list_entrainement.append([X,y])\n",
    "\n",
    "    #this function fits all the hack models (that is to say for every value of y)\n",
    "    def fit_hack_models(self):\n",
    "        for (datas, class_y) in tqdm(zip(self.list_entrainement, self.list_y_class)):\n",
    "            if len(datas[0])>0:\n",
    "                self.hack_models[class_y].fit(datas[0], datas[1])\n",
    "\n",
    "    #this function predicts for every x in X if the model was trained on it or not.\n",
    "    #For every value of y, we use the appropriated hack model\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for class_y in self.list_y_class:\n",
    "            X_class_y = X[X['predic']==class_y]\n",
    "            index = X_class_y.index\n",
    "            if len(X_class_y)>0:\n",
    "                #predictions.append(pd.DataFrame(self.hack_models[class_y].predict(X_class_y), index=index))\n",
    "                try:\n",
    "                    predictions.append(pd.DataFrame(self.hack_models[class_y].predict(X_class_y), index=index))\n",
    "                except NotFittedError as e:\n",
    "                    predictions.append(pd.DataFrame([0]*len(X_class_y), index=index))\n",
    "\n",
    "        return pd.concat(predictions,axis=0)\n",
    "\n",
    "    #this function, given X and y, predicts which elements were in the dataset or not.\n",
    "    #target model is the model we want to hack\n",
    "    def predict_target_model(self, X, y, target_model):\n",
    "        prob = target_model.predict_proba(X)\n",
    "        prob = pd.DataFrame(prob, columns=self.list_y_target_model).reset_index(drop=True)\n",
    "        prob_p = pd.DataFrame([[0]*len(self.list_y_class) for i in range(len(prob))], columns=self.list_y_class)\n",
    "        prob_p[prob.columns] = prob\n",
    "\n",
    "        X = pd.concat([X.reset_index(drop=True), prob_p.reset_index(drop=True)],  axis=1)\n",
    "        X['predic'] = y.reset_index(drop=True)\n",
    "        X.columns = X.columns.astype(str)\n",
    "        return self.predict(X)\n",
    "\n",
    "\n",
    "    #this function gives the classification report of the model\n",
    "    #X_in and y_in were in the training dataset of the target model, X_out and y_out were not\n",
    "    def print_score_hacking(self, X_in, y_in, X_out, y_out, target_model):\n",
    "      res_in = self.predict_target_model(X_in, y_in, target_model)[0]\n",
    "      res_out = self.predict_target_model(X_out, y_out, target_model)[0]\n",
    "      res = np.concatenate((res_in.values,res_out.values))\n",
    "      true_values = [1]*len(res_in) + [0]*len(res_out)\n",
    "\n",
    "      report = classification_report(true_values, res)\n",
    "      print(\"Classification Report, test set:\")\n",
    "      print(report)\n",
    "\n",
    "    def give_constants(self, X_in, y_in, X_out, y_out, target_model):\n",
    "      res_in = self.predict_target_model(X_in, y_in, target_model)[0]\n",
    "      res_out = self.predict_target_model(X_out, y_out, target_model)[0]\n",
    "      res = np.concatenate((res_in.values,res_out.values))\n",
    "      true_values = [1]*len(res_in) + [0]*len(res_out)\n",
    "\n",
    "      report = classification_report(true_values, res,output_dict = True)\n",
    "      return report['accuracy'],report['weighted avg']['f1-score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebecea0-db86-48bd-9b35-c6625aa46217",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(C=100)]*2\n",
    "test = HackingModel(RandomForestClassifier(n_estimators=100),models, X_shadow, y_shadow,\n",
    "                  list(set(y_shadow)),list(set(y_train)) )\n",
    "report=test.print_score_hacking_b(X_train,y_train, X_test,y_test, logistic_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee64289f-074d-4a10-a8e1-a46bb7ae3e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.give_constants(X_train,y_train, X_test,y_test, logistic_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c7ad47-325b-46d4-9a6c-fe4fd4375099",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804eea4-f7f3-4fa7-9b64-84305fb63a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64bfef-5f51-48e3-9b62-4fc5b742d4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
